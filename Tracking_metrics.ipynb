{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Bq-FTraLqPwm",
        "UWgLzkaSlNGB"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/freida20git/bird-detection-tracking/blob/main/Tracking_metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**MOT Metrics to calculate how good is the tracking of the birds**"
      ],
      "metadata": {
        "id": "1Qhik-QsDu52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE:\n",
        "this metrics do not compare the ID numbers directly. The tracker evaluation does not care if your predicted IDs are 1, 100, or 9999. What is measured is how consistently a predicted ID is matched to a ground truth ID across frames based on bounding box overlaps (IoU).\n",
        "\n",
        " so its not a problem if youre predictions have different ID numbers than ground truth."
      ],
      "metadata": {
        "id": "srtTtccdHpCz"
      }
    },
    {
      "source": [
        "!pip install ultralytics==8.0.122"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "cOwW2sFY_dnm",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tracking annotations(prediction and ground truth) in json format (created in tracker.py notebook):\n"
      ],
      "metadata": {
        "id": "stVvzS082XKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1sAuzIr_w0MD-SzqDtwEvlHtlEGoGQIt-\n",
        "!gdown 1TkpvxrVR8Uik4VV_Kw5RPjRn3_LoE49H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHCpSqnYE9am",
        "outputId": "bbf3cb7a-0f9e-4623-c68a-4999ea530228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1sAuzIr_w0MD-SzqDtwEvlHtlEGoGQIt-\n",
            "To: /content/pred_annotations.json\n",
            "100% 348k/348k [00:00<00:00, 68.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1TkpvxrVR8Uik4VV_Kw5RPjRn3_LoE49H\n",
            "To: /content/annotations_gt.json\n",
            "100% 355k/355k [00:00<00:00, 46.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_annotations =\"/content/pred_annotations.json\"\n",
        "gt_annotations = \"/content/annotations_gt.json\""
      ],
      "metadata": {
        "id": "upeykHYI7VIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "!pip install motmetrics\n",
        "import random\n",
        "import cv2\n",
        "import torch\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import Image\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import motmetrics as mm\n",
        "import pandas as pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjGlPX_jxnql",
        "outputId": "57d9a1a2-3312-4504-f2dd-b4f0601cd46c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.122 ðŸš€ Python-3.11.12 torch-2.6.0+cu124 CPU\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 41.2/107.7 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def convert_json_to_mot(json_path, output_path):\n",
        "    with open(json_path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    with open(output_path, \"w\") as f_out:\n",
        "        for frame in data:\n",
        "            frame_number = frame[\"frame_number\"]\n",
        "            for obj in frame[\"objects\"]:\n",
        "                track_id = obj[\"track_id\"]\n",
        "                confidence = obj[\"confidence\"]\n",
        "                class_id = obj[\"class_id\"]\n",
        "\n",
        "                # Extract bounding box\n",
        "                x1, y1 = obj[\"bbox\"][\"x1\"], obj[\"bbox\"][\"y1\"]\n",
        "                x2, y2 = obj[\"bbox\"][\"x2\"], obj[\"bbox\"][\"y2\"]\n",
        "\n",
        "                # Convert to MOT format (x, y, width, height)\n",
        "                width, height = x2 - x1, y2 - y1\n",
        "\n",
        "                # Write in MOT format\n",
        "                f_out.write(f\"{frame_number},{track_id},{x1},{y1},{width},{height},{confidence},{class_id},1\\n\")\n",
        "\n",
        "# Example Usage\n",
        "convert_json_to_mot(\"annotations_gt.json\", \"gt_mot.txt\")\n",
        "convert_json_to_mot('/content/pred_annotations.json', \"pred_annotations.txt\")"
      ],
      "metadata": {
        "id": "2qWf14TBHHP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_tracking_metrics(gt_file, pred_file):\n",
        "    acc = mm.MOTAccumulator(auto_id=True)\n",
        "\n",
        "    # Load GT and prediction files\n",
        "    gt_data = pd.read_csv(gt_file, header=None)\n",
        "    pred_data = pd.read_csv(pred_file, header=None)\n",
        "\n",
        "    frames = sorted(set(gt_data[0]) | set(pred_data[0]))\n",
        "\n",
        "    for frame in frames:\n",
        "        gt_frame = gt_data[gt_data[0] == frame]\n",
        "        pred_frame = pred_data[pred_data[0] == frame]\n",
        "\n",
        "        gt_ids = gt_frame[1].tolist()\n",
        "        pred_ids = pred_frame[1].tolist()\n",
        "\n",
        "        def iou(boxA, boxB):\n",
        "            xA, yA, wA, hA = boxA\n",
        "            xB, yB, wB, hB = boxB\n",
        "            x1, y1 = max(xA, xB), max(yA, yB)\n",
        "            x2, y2 = min(xA + wA, xB + wB), min(yA + hA, yB + hB)\n",
        "            interArea = max(0, x2 - x1) * max(0, y2 - y1)\n",
        "            boxAArea = wA * hA\n",
        "            boxBArea = wB * hB\n",
        "            return 1 - (interArea / float(boxAArea + boxBArea - interArea))\n",
        "\n",
        "        gt_boxes = gt_frame.iloc[:, 2:6].values.tolist()\n",
        "        pred_boxes = pred_frame.iloc[:, 2:6].values.tolist()\n",
        "        distance_matrix = [[iou(gt, pred) for pred in pred_boxes] for gt in gt_boxes]\n",
        "        # Creates a cost matrix where:\n",
        "        # Rows = Ground truth objects.\n",
        "        # Columns = Predicted objects.\n",
        "        # Each cell stores the distance (1 - IoU).\n",
        "        acc.update(gt_ids, pred_ids, distance_matrix)\n",
        "\n",
        "    mh = mm.metrics.create()\n",
        "    summary = mh.compute(acc, metrics=['idf1', 'mota', 'motp', 'num_switches'], name=\"Tracking\")\n",
        "    print(summary)\n",
        "    return summary\n",
        "compute_tracking_metrics(\"/content/gt_mot.txt\", \"/content/pred_annotations.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "nfvqwaKXxvtK",
        "outputId": "feb0c8f7-3912-4e16-f9ba-64439d98d143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              idf1      mota      motp  num_switches\n",
            "Tracking  0.984369  0.978836  0.132966             1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              idf1      mota      motp  num_switches\n",
              "Tracking  0.984369  0.978836  0.132966             1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b4419903-02a5-4d3c-8834-85e9ce9c6677\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idf1</th>\n",
              "      <th>mota</th>\n",
              "      <th>motp</th>\n",
              "      <th>num_switches</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Tracking</th>\n",
              "      <td>0.984369</td>\n",
              "      <td>0.978836</td>\n",
              "      <td>0.132966</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4419903-02a5-4d3c-8834-85e9ce9c6677')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b4419903-02a5-4d3c-8834-85e9ce9c6677 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b4419903-02a5-4d3c-8834-85e9ce9c6677');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"compute_tracking_metrics(\\\"/content/gt_mot\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"idf1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9843690430804423,\n        \"max\": 0.9843690430804423,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9843690430804423\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mota\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9788359788359788,\n        \"max\": 0.9788359788359788,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9788359788359788\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"motp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.1329661106873701,\n        \"max\": 0.1329661106873701,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.1329661106873701\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_switches\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. IDF1 (Identity F1 Score)\n",
        "Measures how well the predicted identities match the ground truth identities.\n",
        "\n",
        "2. MOTA (Multiple Object Tracking Accuracy)\n",
        "Measures overall tracking performance by penalizing missed detections, false positives, and identity switches.\n",
        "\n",
        "3. MOTP (Multiple Object Tracking Precision)\n",
        "Measures the localization precision of tracked objects.\n",
        "It calculates the average overlap (IoU) between matched predictions and ground truth across all frames.\n",
        "\n",
        "Interpretation of Results:\n",
        "\n",
        "High IDF1 â†’ The tracker maintains object identities correctly.\n",
        "\n",
        "High MOTA â†’ The tracker has fewer false positives, false negatives, and ID switches.\n",
        "\n",
        "Low MOTP â†’ The trackerâ€™s bounding boxes are well-aligned with the ground truth.\n",
        "\n"
      ],
      "metadata": {
        "id": "SNxhyjungcP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# turn into coco format for mAP calculation:"
      ],
      "metadata": {
        "id": "UWgLzkaSlNGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# Load your original JSON\n",
        "with open(\"/content/annotations_gt.json\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# COCO template\n",
        "coco_gt = {\n",
        "    \"images\": [],\n",
        "    \"annotations\": [],\n",
        "    \"categories\": [{\"id\": 14, \"name\": \"bird\"}]  # Add all classes here\n",
        "}\n",
        "\n",
        "# Convert each frame\n",
        "for frame in data:  # Assuming `data` is a list of frames\n",
        "    image_id = frame[\"frame_number\"]\n",
        "    coco_gt[\"images\"].append({\n",
        "        \"id\": image_id,\n",
        "        \"file_name\": f\"frame_{image_id:04d}.jpg\",  # Match frame names\n",
        "        \"width\": 1920,  # Set your video width\n",
        "        \"height\": 1080,  # Set your video height\n",
        "    })\n",
        "\n",
        "    for obj in frame[\"objects\"]:\n",
        "        x1, y1, x2, y2 = obj[\"bbox\"][\"x1\"], obj[\"bbox\"][\"y1\"], obj[\"bbox\"][\"x2\"], obj[\"bbox\"][\"y2\"]\n",
        "        coco_gt[\"annotations\"].append({\n",
        "            \"id\": len(coco_gt[\"annotations\"]),  # Unique ID per annotation\n",
        "            \"image_id\": image_id,\n",
        "            \"category_id\": obj[\"class_id\"],\n",
        "            \"bbox\": [x1, y1, x2 - x1, y2 - y1],  # COCO: [x, y, width, height]\n",
        "            \"area\": (x2 - x1) * (y2 - y1),\n",
        "            \"iscrowd\": 0,\n",
        "        })\n",
        "\n",
        "# Save COCO JSON\n",
        "with open(\"coco_gt.json\", \"w\") as f:\n",
        "    json.dump(coco_gt, f)"
      ],
      "metadata": {
        "id": "HXVP1rt5bbiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load trained YOLO model predictions\n",
        "with open(\"pred_annotations.json\") as f:\n",
        "    pred_data = json.load(f)\n",
        "\n",
        "coco_preds = []\n",
        "for frame in pred_data:\n",
        "    for obj in frame[\"objects\"]:\n",
        "        x1, y1, x2, y2 = obj[\"bbox\"][\"x1\"], obj[\"bbox\"][\"y1\"], obj[\"bbox\"][\"x2\"], obj[\"bbox\"][\"y2\"]\n",
        "        coco_preds.append({\n",
        "            \"image_id\": frame[\"frame_number\"],\n",
        "            \"category_id\": 14, #because it detected birds only\n",
        "            \"bbox\": [x1, y1, x2 - x1, y2 - y1],\n",
        "            \"score\": obj[\"confidence\"],  # Critical for mAP calculation\n",
        "        })\n",
        "\n",
        "with open(\"coco_preds.json\", \"w\") as f:\n",
        "    json.dump(coco_preds, f)"
      ],
      "metadata": {
        "id": "eRyc4A50cksP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "\n",
        "# Load ground truth and predictions\n",
        "coco_gt = COCO(\"coco_gt.json\")\n",
        "coco_pred = coco_gt.loadRes(\"coco_preds.json\")\n",
        "\n",
        "# Evaluate\n",
        "coco_eval = COCOeval(coco_gt, coco_pred, \"bbox\")\n",
        "coco_eval.evaluate()\n",
        "coco_eval.accumulate()\n",
        "coco_eval.summarize()  # Prints mAP scores"
      ],
      "metadata": {
        "id": "fJYxPzIRN15s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53ed57ea-b597-403b-8335-a46a94f70596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.32s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.725\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.969\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.860\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.616\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.793\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.246\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.770\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.770\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.660\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.843\n"
          ]
        }
      ]
    }
  ]
}